{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-alstm-dtml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CBMER2hsMnf5441MRMXHzyhEmTp2s0qX",
      "authorship_tag": "ABX9TyOkbjAVBVn2m3SDJ+L8cYdQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andy9705/stock_project/blob/main/lstm_alstm_dtml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFkSVnjzTC0E",
        "outputId": "c98dadc9-4938-484e-97a4-7b5b5367dbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/jolproject/Adv-ALSTM\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/jolproject/Adv-ALSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXetBnELVvoB",
        "outputId": "4c2270d7-6a92-4939-cf14-3c944905f606"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fulifeng/Adv-ALSTM.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUJ3RW_WUGSc",
        "outputId": "3753e5c6-3dcc-42cf-b587-a6ca136335db"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Adv-ALSTM'...\n",
            "remote: Enumerating objects: 357, done.\u001b[K\n",
            "remote: Total 357 (delta 0), reused 0 (delta 0), pack-reused 357\u001b[K\n",
            "Receiving objects: 100% (357/357), 15.80 MiB | 7.67 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "Checking out files: 100% (314/314), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/MyDrive/jolproject/Adv-ALSTM/')"
      ],
      "metadata": {
        "id": "3hiaVE_jTx8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "def load_cla_data(data_path, tra_date, val_date, tes_date, seq=2,\n",
        "                  date_format='%Y-%m-%d'):\n",
        "    fnames = [fname for fname in os.listdir(data_path) if\n",
        "              os.path.isfile(os.path.join(data_path, fname))]\n",
        "    print(len(fnames), ' tickers selected')\n",
        "    print(fnames)\n",
        "    data_EOD = []\n",
        "    for index, fname in enumerate(fnames):\n",
        "        #print(fname)\n",
        "        single_EOD = np.genfromtxt(\n",
        "            os.path.join(data_path, fname), dtype=float, delimiter=',',\n",
        "            skip_header=False\n",
        "        )\n",
        "        #print('data shape:', single_EOD.shape)\n",
        "        data_EOD.append(single_EOD)\n",
        "    print(len(data_EOD)) #50\n",
        "    print(len(data_EOD[0])) #2518\n",
        "    print(len(data_EOD[0][0])) #13\n",
        "\n",
        "\n",
        "    fea_dim = data_EOD[0].shape[1] - 2\n",
        "\n",
        "    trading_dates = np.genfromtxt(\n",
        "        os.path.join(data_path, '..', 'trading_dates.csv'), dtype=str,\n",
        "        delimiter=',', skip_header=False\n",
        "    )\n",
        "    print(len(trading_dates), 'trading dates:')\n",
        "\n",
        "    # transform the trading dates into a dictionary with index, at the same\n",
        "    # time, transform the indices into a dictionary with weekdays\n",
        "    dates_index = {}\n",
        "    # indices_weekday = {}\n",
        "    data_wd = np.zeros([len(trading_dates), 5], dtype=float)\n",
        "    wd_encodings = np.identity(5, dtype=float)\n",
        "    for index, date in enumerate(trading_dates):\n",
        "        dates_index[date] = index\n",
        "        # indices_weekday[index] = datetime.strptime(date, date_format).weekday()\n",
        "        data_wd[index] = wd_encodings[datetime.strptime(date, date_format).weekday()]\n",
        "\n",
        "    tra_ind = dates_index[tra_date]\n",
        "    val_ind = dates_index[val_date]\n",
        "    tes_ind = dates_index[tes_date]\n",
        "    print(tra_ind, val_ind, tes_ind) #0 2014 2266\n",
        "\n",
        "    # count training, validation, and testing instances\n",
        "    tra_num = 0\n",
        "    val_num = 0\n",
        "    tes_num = 0\n",
        "    # training\n",
        "    temp=[]\n",
        "    for date_ind in range(tra_ind, val_ind):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        \n",
        "        for tic_ind in range(len(fnames)):\n",
        "            #print(abs(data_EOD[tic_ind][date_ind][-2]))\n",
        "            \n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                tra_num += 1\n",
        "            else:\n",
        "\n",
        "              temp.append([date_ind,tic_ind])\n",
        "    print(temp)\n",
        "    print(len(temp))\n",
        "    print(tra_num, ' training instances')\n",
        "\n",
        "    # validation\n",
        "    for date_ind in range(val_ind, tes_ind):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            \n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                val_num += 1\n",
        "    print(val_num, ' validation instances')\n",
        "\n",
        "    # testing\n",
        "    for date_ind in range(tes_ind, len(trading_dates)):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            \n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                tes_num += 1\n",
        "    print(tes_num, ' testing instances')\n",
        "\n",
        "    # generate training, validation, and testing instances\n",
        "    # training\n",
        "    tra_pv = np.zeros([tra_num, seq, fea_dim], dtype=float)\n",
        "    tra_wd = np.zeros([tra_num, seq, 5], dtype=float)\n",
        "    tra_gt = np.zeros([tra_num, 1], dtype=float)\n",
        "    ins_ind = 0\n",
        "    for date_ind in range(tra_ind, val_ind):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            \n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                tra_pv[ins_ind] = data_EOD[tic_ind][date_ind - seq: date_ind, : -2]\n",
        "                tra_wd[ins_ind] = data_wd[date_ind - seq: date_ind, :]\n",
        "                tra_gt[ins_ind, 0] = data_EOD[tic_ind][date_ind][-2]  #ground truth\n",
        "                # print(data_EOD[tic_ind][date_ind - seq: date_ind, : -2])\n",
        "                # print(data_wd[date_ind - seq: date_ind, :])\n",
        "                # print((data_EOD[tic_ind][date_ind][-2] + 1) / 2)\n",
        "                # print(date_ind)\n",
        "                \n",
        "                ins_ind += 1\n",
        "\n",
        "    # validation\n",
        "    val_pv = np.zeros([val_num, seq, fea_dim], dtype=float)\n",
        "    val_wd = np.zeros([val_num, seq, 5], dtype=float)\n",
        "    val_gt = np.zeros([val_num, 1], dtype=float)\n",
        "    ins_ind = 0\n",
        "    for date_ind in range(val_ind, tes_ind):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                val_pv[ins_ind] = data_EOD[tic_ind][date_ind - seq: date_ind, :-2]\n",
        "                val_wd[ins_ind] = data_wd[date_ind - seq: date_ind, :]\n",
        "                val_gt[ins_ind, 0] = data_EOD[tic_ind][date_ind][-2] \n",
        "                ins_ind += 1\n",
        "\n",
        "    # testing\n",
        "    tes_pv = np.zeros([tes_num, seq, fea_dim], dtype=float)\n",
        "    tes_wd = np.zeros([tes_num, seq, 5], dtype=float)\n",
        "    tes_gt = np.zeros([tes_num, 1], dtype=float)\n",
        "    ins_ind = 0\n",
        "    for date_ind in range(tes_ind, len(trading_dates)):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                tes_pv[ins_ind] = data_EOD[tic_ind][date_ind - seq: date_ind, :-2]\n",
        "                # # for the momentum indicator\n",
        "                # tes_pv[ins_ind, -1, -1] = data_EOD[tic_ind][date_ind - 1, -1] - data_EOD[tic_ind][date_ind - 11, -1]\n",
        "                tes_wd[ins_ind] = data_wd[date_ind - seq: date_ind, :]\n",
        "                tes_gt[ins_ind, 0] = data_EOD[tic_ind][date_ind][-2] \n",
        "                ins_ind += 1\n",
        "    return tra_pv, tra_wd, tra_gt, val_pv, val_wd, val_gt, tes_pv, tes_wd, tes_gt\n",
        "\n",
        "\n",
        "def load_globalmarket_data(data_path, tra_date, val_date, tes_date, seq=2,\n",
        "                  date_format='%Y-%m-%d'):\n",
        "    fnames = [fname for fname in os.listdir(data_path) if\n",
        "              os.path.isfile(os.path.join(data_path, fname))]\n",
        "    print(len(fnames), ' tickers selected')\n",
        "    print(fnames)\n",
        "    data_EOD = []\n",
        "    for index, fname in enumerate(fnames):\n",
        "        #print(fname)\n",
        "        single_EOD = np.genfromtxt(\n",
        "            os.path.join(data_path, fname), dtype=float, delimiter=',',\n",
        "            skip_header=False\n",
        "        )\n",
        "        #print('data shape:', single_EOD.shape)\n",
        "        data_EOD.append(single_EOD)\n",
        "    print(len(data_EOD)) #50\n",
        "    print(len(data_EOD[0])) #2518\n",
        "    print(len(data_EOD[0][0])) #11\n",
        "\n",
        "\n",
        "    fea_dim = data_EOD[0].shape[1] \n",
        "\n",
        "    trading_dates = np.genfromtxt(\n",
        "        os.path.join(data_path, '..', 'trading_dates.csv'), dtype=str,\n",
        "        delimiter=',', skip_header=False\n",
        "    )\n",
        "    print(len(trading_dates), 'trading dates:')\n",
        "\n",
        "    # transform the trading dates into a dictionary with index, at the same\n",
        "    # time, transform the indices into a dictionary with weekdays\n",
        "    dates_index = {}\n",
        "    # indices_weekday = {}\n",
        "    data_wd = np.zeros([len(trading_dates), 5], dtype=float)\n",
        "    wd_encodings = np.identity(5, dtype=float)\n",
        "    for index, date in enumerate(trading_dates):\n",
        "        dates_index[date] = index\n",
        "        # indices_weekday[index] = datetime.strptime(date, date_format).weekday()\n",
        "        data_wd[index] = wd_encodings[datetime.strptime(date, date_format).weekday()]\n",
        "\n",
        "    tra_ind = dates_index[tra_date]\n",
        "    val_ind = dates_index[val_date]\n",
        "    tes_ind = dates_index[tes_date]\n",
        "    print(tra_ind, val_ind, tes_ind) #0 2014 2266\n",
        "\n",
        "    # count training, validation, and testing instances\n",
        "    tra_num = 0\n",
        "    val_num = 0\n",
        "    tes_num = 0\n",
        "    # training\n",
        "    \n",
        "    \n",
        "    for date_ind in range(tra_ind, val_ind):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        \n",
        "        for tic_ind in range(len(fnames)):\n",
        "            #print(abs(data_EOD[tic_ind][date_ind][-2]))\n",
        "            \n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                tra_num += 1\n",
        "                \n",
        "    print(tra_num, ' training instances')\n",
        "\n",
        "    # validation\n",
        "    for date_ind in range(val_ind, tes_ind):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            \n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                val_num += 1\n",
        "    print(val_num, ' validation instances')\n",
        "\n",
        "    # testing\n",
        "    for date_ind in range(tes_ind, len(trading_dates)):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            \n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                tes_num += 1\n",
        "    print(tes_num, ' testing instances')\n",
        "\n",
        "    # generate training, validation, and testing instances\n",
        "    # training\n",
        "    tra_pv = np.zeros([tra_num, seq, fea_dim], dtype=float)\n",
        "    tra_wd = np.zeros([tra_num, seq, 5], dtype=float)\n",
        "    tra_gt = np.zeros([tra_num, 1], dtype=float)\n",
        "    ins_ind = 0\n",
        "    for date_ind in range(tra_ind, val_ind):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            \n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                tra_pv[ins_ind] = data_EOD[tic_ind][date_ind - seq: date_ind, : ]\n",
        "                tra_wd[ins_ind] = data_wd[date_ind - seq: date_ind, :]\n",
        "                tra_gt[ins_ind, 0] = data_EOD[tic_ind][date_ind][-2]  #ground truth\n",
        "                # print(data_EOD[tic_ind][date_ind - seq: date_ind, : -2])\n",
        "                # print(data_wd[date_ind - seq: date_ind, :])\n",
        "                # print((data_EOD[tic_ind][date_ind][-2] + 1) / 2)\n",
        "                # print(date_ind)\n",
        "                \n",
        "                ins_ind += 1\n",
        "\n",
        "    # validation\n",
        "    val_pv = np.zeros([val_num, seq, fea_dim], dtype=float)\n",
        "    val_wd = np.zeros([val_num, seq, 5], dtype=float)\n",
        "    val_gt = np.zeros([val_num, 1], dtype=float)\n",
        "    ins_ind = 0\n",
        "    for date_ind in range(val_ind, tes_ind):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                val_pv[ins_ind] = data_EOD[tic_ind][date_ind - seq: date_ind, :]\n",
        "                val_wd[ins_ind] = data_wd[date_ind - seq: date_ind, :]\n",
        "                val_gt[ins_ind, 0] = data_EOD[tic_ind][date_ind][-2] \n",
        "                ins_ind += 1\n",
        "\n",
        "    # testing\n",
        "    tes_pv = np.zeros([tes_num, seq, fea_dim], dtype=float)\n",
        "    tes_wd = np.zeros([tes_num, seq, 5], dtype=float)\n",
        "    tes_gt = np.zeros([tes_num, 1], dtype=float)\n",
        "    ins_ind = 0\n",
        "    for date_ind in range(tes_ind, len(trading_dates)):\n",
        "        # filter out instances without length enough history\n",
        "        if date_ind < seq:\n",
        "            continue\n",
        "        for tic_ind in range(len(fnames)):\n",
        "            if data_EOD[tic_ind][date_ind - seq: date_ind, :].min() > -123320:\n",
        "                tes_pv[ins_ind] = data_EOD[tic_ind][date_ind - seq: date_ind, :]\n",
        "                # # for the momentum indicator\n",
        "                # tes_pv[ins_ind, -1, -1] = data_EOD[tic_ind][date_ind - 1, -1] - data_EOD[tic_ind][date_ind - 11, -1]\n",
        "                tes_wd[ins_ind] = data_wd[date_ind - seq: date_ind, :]\n",
        "                tes_gt[ins_ind, 0] = data_EOD[tic_ind][date_ind][-2] \n",
        "                ins_ind += 1\n",
        "    return tra_pv, tra_wd, tra_gt, val_pv, val_wd, val_gt, tes_pv, tes_wd, tes_gt"
      ],
      "metadata": {
        "id": "FYYdkotKVGUT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from load import load_cla_data\n",
        "\n",
        "\n",
        "# if 'acl18' in args.path:\n",
        "#         tra_date = '2014-01-02'\n",
        "#         val_date = '2015-08-03'\n",
        "#         tes_date = '2015-10-01'\n",
        "#     elif 'kdd17' in args.path:\n",
        "#         tra_date = '2007-01-03'\n",
        "#         val_date = '2015-01-02'\n",
        "#         tes_date = '2016-01-04'\n",
        "\n",
        "# tra_date = '2007-01-03'\n",
        "# val_date = '2015-01-02'\n",
        "# tes_date = '2016-01-04'\n",
        "\n",
        "tra_date = '2014-01-02'\n",
        "val_date = '2015-08-03'\n",
        "tes_date = '2015-10-01'\n",
        "\n",
        "tra_pv, tra_wd,tra_gt, \\\n",
        "val_pv, val_wd, val_gt, \\\n",
        "tes_pv, tes_wd, tes_gt = load_cla_data(\n",
        "    \"./data/stocknet-dataset/price/ourpped/\",  #ACL18 ./data/stocknet-dataset/price/ourpped/, KDD ./data/kdd17/ourpped/\n",
        "    tra_date, val_date, tes_date, seq=10  ##10, 15 window size\n",
        ")\n",
        "fea_dim = tra_pv.shape[2]\n",
        "\n",
        "globaltra_pv, globaltra_wd,globaltra_gt, \\\n",
        "globalval_pv, globalval_wd, globalval_gt, \\\n",
        "globaltes_pv, globaltes_wd, globaltes_gt = load_globalmarket_data(\n",
        "    \"./data/stocknet-dataset/price/globalmarket/\",  #ACL18 ./data/stocknet-dataset/price/ourpped, KDD ./data/kdd17/ourpped/\n",
        "    tra_date, val_date, tes_date, seq=10  ##10, 15 window size\n",
        ")\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjauUi-pZZXG",
        "outputId": "3301dfee-857e-481f-878f-90ea6775c3bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85  tickers selected\n",
            "['AAPL.csv', 'ABBV.csv', 'AEP.csv', 'ABB.csv', 'AMGN.csv', 'AMZN.csv', 'BA.csv', 'BAC.csv', 'BCH.csv', 'BBL.csv', 'BHP.csv', 'BRK-A.csv', 'BP.csv', 'BSAC.csv', 'BUD.csv', 'C.csv', 'CAT.csv', 'CELG.csv', 'CHL.csv', 'CHTR.csv', 'CMCSA.csv', 'CODI.csv', 'CVX.csv', 'CSCO.csv', 'D.csv', 'DHR.csv', 'DIS.csv', 'EXC.csv', 'FB.csv', 'GD.csv', 'DUK.csv', 'GE.csv', 'GOOG.csv', 'HSBC.csv', 'HRG.csv', 'HON.csv', 'HD.csv', 'IEP.csv', 'JPM.csv', 'JNJ.csv', 'INTC.csv', 'KO.csv', 'LMT.csv', 'MMM.csv', 'MA.csv', 'MCD.csv', 'MDT.csv', 'MO.csv', 'MSFT.csv', 'MRK.csv', 'NEE.csv', 'NGG.csv', 'NVS.csv', 'ORCL.csv', 'PCG.csv', 'PEP.csv', 'PCLN.csv', 'PFE.csv', 'PG.csv', 'PICO.csv', 'PTR.csv', 'PM.csv', 'PPL.csv', 'RDS-B.csv', 'SNP.csv', 'SLB.csv', 'REX.csv', 'SNY.csv', 'SO.csv', 'T.csv', 'SRE.csv', 'TM.csv', 'SPLP.csv', 'TOT.csv', 'UN.csv', 'UNH.csv', 'UL.csv', 'TSM.csv', 'UPS.csv', 'UTX.csv', 'WFC.csv', 'VZ.csv', 'V.csv', 'XOM.csv', 'WMT.csv']\n",
            "85\n",
            "652\n",
            "13\n",
            "652 trading dates:\n",
            "148 546 588\n",
            "[]\n",
            "0\n",
            "33830  training instances\n",
            "3570  validation instances\n",
            "5440  testing instances\n",
            "1  tickers selected\n",
            "['sp500_acl18.csv']\n",
            "1\n",
            "652\n",
            "11\n",
            "652 trading dates:\n",
            "148 546 588\n",
            "398  training instances\n",
            "42  validation instances\n",
            "64  testing instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(globaltra_pv,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aeoc-3dnJraa",
        "outputId": "25587780-59f3-4e0c-dfad-45e77a0c35a5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.03624 ,  1.92064 , -0.525452,  0.895792,  0.895792,  0.978439,\n",
              "          0.869724, -0.945822, -1.990395, -2.686717, -5.082441],\n",
              "        [ 0.271055,  0.560177, -0.758948,  0.27179 ,  0.27179 ,  0.05421 ,\n",
              "          0.914347, -0.88664 , -1.998555, -2.682327, -4.737381],\n",
              "        [-0.072439,  0.452735, -1.032233, -0.21684 , -0.21684 ,  0.068814,\n",
              "          1.291197, -0.231802, -1.568274, -2.218039, -3.889293],\n",
              "        [-1.122989,  0.39216 , -1.693398,  1.59362 ,  1.59362 , -1.408196,\n",
              "         -0.19964 , -1.292926, -2.757573, -3.546521, -4.761137],\n",
              "        [ 0.682106,  0.682106, -0.125651, -0.695185, -0.695185, -0.355411,\n",
              "          0.217197, -0.268054, -1.763596, -2.647279, -3.485907],\n",
              "        [ 0.017934,  0.50224 , -0.44843 ,  0.071802,  0.071802, -0.22601 ,\n",
              "         -0.130942, -0.171002, -1.512108, -2.425112, -3.091181],\n",
              "        [-0.321658,  0.035742, -0.607577,  0.37668 ,  0.37668 , -0.378841,\n",
              "         -0.716582, -0.262091, -1.583272, -2.543244, -3.196925],\n",
              "        [-0.089364,  0.268091, -0.196606, -0.017866, -0.017866, -0.100092,\n",
              "         -0.668456, -0.053622, -1.175159, -2.302058, -2.928212],\n",
              "        [ 1.193059,  1.373829, -0.090383, -1.126007, -1.126007,  0.755603,\n",
              "          0.368763,  1.056881,  0.263015, -0.958062, -1.696192],\n",
              "        [ 0.638218,  1.13056 , -0.656455, -0.867679, -0.867679,  1.320204,\n",
              "          1.272793,  1.644784,  1.315645,  0.099927, -0.699003]]),\n",
              " array([-123321.]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd \n",
        "from pylab import mpl, plt\n",
        "plt.style.use('seaborn')\n",
        "mpl.rcParams['font.family'] = 'serif'\n",
        "%matplotlib inline\n",
        "\n",
        "from pandas import datetime\n",
        "import math, time\n",
        "import itertools\n",
        "import datetime\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import sqrt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09bCOxPN769t",
        "outputId": "a64c681f-f630-4a68-c042-cfb9d0cf0bd0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "x_train = torch.from_numpy(tra_pv).type(torch.Tensor).to(device)\n",
        "x_test = torch.from_numpy(tes_pv).type(torch.Tensor).to(device)\n",
        "y_train = torch.from_numpy(tra_gt).type(torch.Tensor).to(device)\n",
        "y_test = torch.from_numpy(tes_gt).type(torch.Tensor).to(device)\n",
        "x_val = torch.from_numpy(val_pv).type(torch.Tensor).to(device)\n",
        "y_val = torch.from_numpy(val_gt).type(torch.Tensor).to(device)\n",
        "\n",
        "global_train = torch.from_numpy(globaltra_pv).type(torch.Tensor).to(device)\n",
        "global_val = torch.from_numpy(globalval_pv).type(torch.Tensor).to(device)\n",
        "global_test = torch.from_numpy(globaltes_pv).type(torch.Tensor).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD55Ft197umz",
        "outputId": "cbe46b66-eb2f-45a4-e200-9e7f882e98d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.size(),x_train.size(),global_train.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAWiWaMA8VQq",
        "outputId": "893f3233-d889-4690-83ba-da0ffdfcab0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([33830, 1]),\n",
              " torch.Size([33830, 10, 11]),\n",
              " torch.Size([398, 10, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(y_true, y_prob):\n",
        "    \n",
        "    y_prob = y_prob > 0.0\n",
        "    \n",
        "    return (y_true == y_prob).sum().item() / y_true.size(0)"
      ],
      "metadata": {
        "id": "63c14ellJNsp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "#####################\n",
        "input_dim = 11\n",
        "hidden_dim = 32\n",
        "num_layers = 1 \n",
        "output_dim = 1\n",
        "\n",
        "\n",
        "# Here we define our model as a class\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        #feature transformerlayer\n",
        "        self.feature_transformer=nn.Linear(input_dim,input_dim)\n",
        "        self.tanh_layer=nn.Tanh()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        x=self.feature_transformer(x)\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        x=self.tanh_layer(x)\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        #print(out.shape)  #98750, 10 ,32\n",
        "        #input()\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 32, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
        "        #print(out[:, -1, :])\n",
        "        #print(out[:, -1, :].shape) #98750, 32\n",
        "        #input() \n",
        "        out = self.fc(out[:, -1, :])\n",
        "        #print(out)\n",
        "        #print(out.shape)\n",
        "        #input() \n",
        "        # out.size() --> 100, 10\n",
        "        return out\n",
        "    \n",
        "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers).to(device)\n",
        "\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(model)\n",
        "print(len(list(model.parameters())))\n",
        "for i in range(len(list(model.parameters()))):\n",
        "    print(list(model.parameters())[i].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYP20v7u9GGK",
        "outputId": "0dab551b-b39d-4648-c735-a5d2e90f3b54"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (feature_transformer): Linear(in_features=11, out_features=11, bias=True)\n",
            "  (tanh_layer): Tanh()\n",
            "  (lstm): LSTM(11, 32, batch_first=True)\n",
            "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n",
            "8\n",
            "torch.Size([11, 11])\n",
            "torch.Size([11])\n",
            "torch.Size([128, 11])\n",
            "torch.Size([128, 32])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([1, 32])\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "#####################\n",
        "num_epochs = 200\n",
        "hist = np.zeros(num_epochs)\n",
        "seq=10\n",
        "# Number of steps to unroll\n",
        "seq_dim =seq-1  \n",
        "\n",
        "patience=15\n",
        "check_early_stopping=0\n",
        "val_accuracy=0\n",
        "for t in range(num_epochs):\n",
        "    # Initialise hidden state\n",
        "    # Don't do this if you want your LSTM to be stateful\n",
        "    #model.hidden = model.init_hidden()\n",
        "    model.train()\n",
        "    # Forward pass\n",
        "    y_train_pred = model(x_train)\n",
        "    # print(y_train_pred)\n",
        "    # print(y_train_pred.shape)\n",
        "    # print(y_train)\n",
        "    # print(y_train.shape)\n",
        "    \n",
        "    loss = loss_fn(y_train_pred, y_train)\n",
        "    \n",
        "    \n",
        "    if t % 10 == 0 and t !=0:\n",
        "        print(\"Epoch \", t, \"CE: \", loss.item())\n",
        "    hist[t] = loss.item()\n",
        "    print(loss)\n",
        "    # Zero out gradient, else they will accumulate between epochs\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimiser.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct=0\n",
        "    with torch.no_grad():\n",
        "      y_val_pred=model(x_val)\n",
        "      #print(y_val_pred)\n",
        "      #print(get_accuracy(y_val,y_val_pred))\n",
        "      if val_accuracy <get_accuracy(y_val,y_val_pred):\n",
        "        val_accuracy=get_accuracy(y_val,y_val_pred)\n",
        "        check_early_stopping=0\n",
        "      else:\n",
        "        check_early_stopping=check_early_stopping+1\n",
        "    if check_early_stopping==patience:\n",
        "      print(\"early stopping!\")\n",
        "      print(val_accuracy)\n",
        "      print(\"epochs: \",t)\n",
        "      break\n",
        "#test score\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_test_pred=model(x_test)\n",
        "    print(get_accuracy(y_test,y_test_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPK5Bkh8D3VU",
        "outputId": "767e1e1e-267b-49e8-de1f-a9b5debcb503"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6945, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6941, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6937, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6934, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6931, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6929, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6928, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6927, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch  10 CE:  0.6925055384635925\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "early stopping!\n",
            "0.5184873949579832\n",
            "epochs:  17\n",
            "0.5066176470588235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "#####################\n",
        "input_dim = 11\n",
        "hidden_dim = 32\n",
        "num_layers = 1 \n",
        "output_dim = 1\n",
        "\n",
        "\n",
        "# Here we define our model as a class\n",
        "class ALSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(ALSTM, self).__init__()\n",
        "        self.softmax_layer=nn.Softmax(dim=1)\n",
        "        #feature transformerlayer\n",
        "        self.feature_transformer=nn.Linear(input_dim,input_dim)\n",
        "        self.tanh_layer=nn.Tanh()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        x=self.feature_transformer(x)\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        x=self.tanh_layer(x)\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        sumscore=0\n",
        "        scorelist=[]\n",
        "        #print(out[:,-1,:].shape)#torch.Size([98750, 32])\n",
        "        #print(out[:,:,:].shape) #torch.Size([98750, 10, 32])\n",
        "        \n",
        "        base=out[:,-1,:].view(-1,1,self.hidden_dim)\n",
        "        #print(base.shape)\n",
        "        #print(base.transpose(1,2))\n",
        "        #print(base.transpose(1,2).shape)\n",
        "        #input()\n",
        "        base=base.transpose(1,2)\n",
        "        score=torch.bmm(out,base)\n",
        "        #print(score.shape) #torch.Size([98750, 10, 1])\n",
        "        #print(score[0])\n",
        "        score = self.softmax_layer(score) #softmax score까지함 \n",
        "        #print(score[0])\n",
        "        #print(score.shape) #torch.Size([98750, 10, 1])\n",
        "        transpose_out=out[:,:,:].transpose(1,2) #torch.Size([98750, 32, 10])\n",
        "        new_out=torch.bmm(transpose_out,score)\n",
        "        #print(new_out.shape)\n",
        "        new_out=new_out.view(-1,self.hidden_dim)\n",
        "        #print(new_out.shape)\n",
        "        #input()\n",
        "        # for i in range(seq):\n",
        "        #   print(out[:,i,:].shape)\n",
        "        #   print(base.shape)\n",
        "        #   score=torch.bmm(out[:,i,:],base)\n",
        "        #   print(score.shape)\n",
        "        #   scorelist.append(score)\n",
        "        #   sumscore=sumscore+score\n",
        "        # print(scorelist)\n",
        "        # print(sumscore)\n",
        "        # input()\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 32, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
        "        #print(out[:, -1, :])\n",
        "        #print(out[:, -1, :].shape) \n",
        "        out = self.fc(new_out)\n",
        "        \n",
        "        #input() \n",
        "        # out.size() --> 100, 10\n",
        "        return out\n",
        "    \n",
        "model = ALSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers).to(device)\n",
        "\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(model)\n",
        "print(len(list(model.parameters())))\n",
        "for i in range(len(list(model.parameters()))):\n",
        "    print(list(model.parameters())[i].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjJLiF8r2FT4",
        "outputId": "f60d7a91-094e-4469-c3dd-f59ed5296032"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALSTM(\n",
            "  (softmax_layer): Softmax(dim=1)\n",
            "  (feature_transformer): Linear(in_features=11, out_features=11, bias=True)\n",
            "  (tanh_layer): Tanh()\n",
            "  (lstm): LSTM(11, 32, batch_first=True)\n",
            "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n",
            "8\n",
            "torch.Size([11, 11])\n",
            "torch.Size([11])\n",
            "torch.Size([128, 11])\n",
            "torch.Size([128, 32])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([1, 32])\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "#####################\n",
        "num_epochs = 200\n",
        "hist = np.zeros(num_epochs)\n",
        "seq=10\n",
        "# Number of steps to unroll\n",
        "seq_dim =seq-1  \n",
        "\n",
        "patience=15\n",
        "check_early_stopping=0\n",
        "val_accuracy=0\n",
        "for t in range(num_epochs):\n",
        "    # Initialise hidden state\n",
        "    # Don't do this if you want your LSTM to be stateful\n",
        "    #model.hidden = model.init_hidden()\n",
        "    model.train()\n",
        "    # Forward pass\n",
        "    y_train_pred = model(x_train)\n",
        "    # print(y_train_pred)\n",
        "    # print(y_train_pred.shape)\n",
        "    # print(y_train)\n",
        "    # print(y_train.shape)\n",
        "    \n",
        "    loss = loss_fn(y_train_pred, y_train)\n",
        "    \n",
        "    \n",
        "    if t % 10 == 0 and t !=0:\n",
        "        print(\"Epoch \", t, \"CE: \", loss.item())\n",
        "    hist[t] = loss.item()\n",
        "    print(loss)\n",
        "    # Zero out gradient, else they will accumulate between epochs\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimiser.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct=0\n",
        "    with torch.no_grad():\n",
        "      y_val_pred=model(x_val)\n",
        "      #print(y_val_pred)\n",
        "      #print(get_accuracy(y_val,y_val_pred))\n",
        "      if val_accuracy <get_accuracy(y_val,y_val_pred):\n",
        "        val_accuracy=get_accuracy(y_val,y_val_pred)\n",
        "        check_early_stopping=0\n",
        "      else:\n",
        "        check_early_stopping=check_early_stopping+1\n",
        "    if check_early_stopping==patience:\n",
        "      print(\"early stopping!\")\n",
        "      print(val_accuracy)\n",
        "      print(\"epochs: \",t)\n",
        "      break\n",
        "#test score\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_test_pred=model(x_test)\n",
        "    print(get_accuracy(y_test,y_test_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hos4zGWDEB6F",
        "outputId": "17f0e796-1751-4276-dca1-5c458d55dc14"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6933, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6930, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6928, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6927, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch  10 CE:  0.6925828456878662\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch  20 CE:  0.6923807859420776\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "early stopping!\n",
            "0.4823529411764706\n",
            "epochs:  25\n",
            "0.49926470588235294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout,device \n",
        "                                                  ) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        \n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout,device \n",
        "                 ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout,device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.MLP1=nn.Linear(hid_dim,pf_dim)\n",
        "        self.MLP2=nn.Linear(pf_dim,hid_dim)\n",
        "        self.tanh_layer=nn.Tanh()\n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src) #_src H물결  src H\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        t=self.MLP1(src+_src)\n",
        "        t = torch.nn.functional.relu(t)\n",
        "        t=self.dropout(t)\n",
        "        t=self.MLP2(t)\n",
        "        t=torch.nn.functional.relu(t)\n",
        "        t=self.dropout(t)\n",
        "        \n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        src = self.tanh_layer(t+src+_src) #\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src)\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout,device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        #self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention\n",
        "\n",
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        new_x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        new_x = self.fc_2(new_x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "Y_ixwlbdZgG9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hos5_L8i6O4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "#####################\n",
        "\n",
        "#the window size𝑤 in {10, 15}, the market context weight\n",
        "# 𝛽 in {0.01, 0.1, 1}, the hidden layer size ℎ in {64, 128}, the number\n",
        "# of epochs in {100, 200}, and the learning rate in {0.001, 0.0001}. We\n",
        "# set the strength 𝜆 of selective regularization to 1 and the dropout\n",
        "# rate to 0.15. We use the Adam optimizer [14] for the training with\n",
        "# the early stopping by the validation accuracy. For competitors, we\n",
        "# use the default settings in their public implementations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Here we define our model as a class\n",
        "class DTML(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim,encoder):\n",
        "        super(DTML, self).__init__()\n",
        "        self.softmax_layer=nn.Softmax(dim=1)\n",
        "        #feature transformerlayer\n",
        "        self.feature_transformer=nn.Linear(input_dim,input_dim)\n",
        "        self.tanh_layer=nn.Tanh()\n",
        "        #self.global_train=global_train\n",
        "\n",
        "        self.global_feature_transformer=nn.Linear(input_dim,input_dim)\n",
        "        self.global_tanh_layer=nn.Tanh()\n",
        "\n",
        "        self.layer_nomalization= nn.LayerNorm(hidden_dim)\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.stocklstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.globallstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "\n",
        "        #transformer\n",
        "        self.encoder=encoder\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x,numbers,global_train,beta):\n",
        "        #print(numbers)\n",
        "        #input()\n",
        "        # Initialize hidden state with zeros\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        x=self.feature_transformer(x)\n",
        "        #input()\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        x=self.tanh_layer(x)\n",
        "\n",
        "        global_train=self.global_feature_transformer(global_train)\n",
        "        #print(global_train)\n",
        "        #print(global_train.shape)\n",
        "        global_train=self.global_tanh_layer(global_train)\n",
        "        \n",
        "        #print(x)\n",
        "        #print(x.shape) #torch.Size([98750, 10, 11])\n",
        "        #input()\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "\n",
        "        #input()\n",
        "        global_h0 = torch.zeros(self.num_layers, global_train.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "        global_c0 = torch.zeros(self.num_layers, global_train.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        #print(x)\n",
        "        #print(x.shape)\n",
        "        out, (hn, cn) = self.stocklstm(x, (h0.detach(), c0.detach()))\n",
        "        #input()\n",
        "        global_out, (global_hn,global_cn) = self.globallstm(global_train,(global_h0.detach(), global_c0.detach()))\n",
        "\n",
        "        #print(global_out.shape) #torch.Size([1975, 10, 32])\n",
        "\n",
        "        #global market attention\n",
        "        global_base=global_out[:,-1,:].view(-1,1,self.hidden_dim)\n",
        "        global_base=global_base.transpose(1,2)\n",
        "        global_score=torch.bmm(global_out,global_base)\n",
        "        global_score = self.softmax_layer(global_score) #softmax score까지함\n",
        "        global_transpose_out=global_out[:,:,:].transpose(1,2) #torch.Size([98750, 32, 10])\n",
        "        global_new_out=torch.bmm(global_transpose_out,global_score)\n",
        "        global_new_out=global_new_out.view(-1,self.hidden_dim)\n",
        "        #print(global_new_out)\n",
        "        #print(global_new_out.shape) #torch.Size([1975, 32])\n",
        "        #print(len(global_new_out))\n",
        "        \n",
        "\n",
        "\n",
        "        sumscore=0\n",
        "        scorelist=[]\n",
        "        #print(out[:,-1,:].shape)#torch.Size([98750, 32])\n",
        "        #print(out[:,:,:].shape) #torch.Size([98750, 10, 32])\n",
        "        \n",
        "\n",
        "        #stock attention\n",
        "        base=out[:,-1,:].view(-1,1,self.hidden_dim)\n",
        "        base=base.transpose(1,2)\n",
        "        score=torch.bmm(out,base)\n",
        "        score = self.softmax_layer(score) #softmax score까지함\n",
        "        transpose_out=out[:,:,:].transpose(1,2) #torch.Size([98750, 32, 10])\n",
        "        new_out=torch.bmm(transpose_out,score)\n",
        "        new_out=new_out.view(-1,self.hidden_dim)\n",
        "        #print(new_out)\n",
        "        #print(new_out.shape) #torch.Size([98750, 32])\n",
        "        #new_out=self.layer_nomalization(new_out)\n",
        "        myindex=0\n",
        "        for i in range(85):  #ACL 85, KDD 50\n",
        "          for j in range(len(global_new_out)):\n",
        "            \n",
        "            \n",
        "            new_out[myindex]=new_out[myindex]+global_new_out[j]*beta\n",
        "            \n",
        "        \n",
        "        #print(new_out.shape) #torch.Size([98750, 32]) H: 50,32  W size:32x32  H를 layer 3개에 넣어서 Q,K,V를 만듦 50x32 \n",
        "        #만들어야할것 98750,50,32 형태\n",
        "        #print(new_out[0].shape)\n",
        "        temp1=new_out[0]\n",
        "        temp2=new_out[1]\n",
        "        #print(temp1,temp2)\n",
        "        temp3=torch.stack([temp1,temp2],0)\n",
        "        #print(temp3)\n",
        "        #print(temp3.shape)  #1975,50,32를 만들고 싶음\n",
        "        new_data_list=[]\n",
        "        #print(len(global_new_out))\n",
        "        #input()\n",
        "        for i in range(len(global_new_out)):\n",
        "          temp=[]\n",
        "          for j in range(85): #ACL 85, KDD 50\n",
        "            temp.append(new_out[i+numbers*j])\n",
        "          ttt=torch.stack(temp,0)  #1,50,32\n",
        "          new_data_list.append(ttt)\n",
        "          #Q K 내적 50x32 32x50 -> 50x50 attention map 만들고 attention map softmax 취한 후 value와 곱하면 50x32 query attention이 됨 이걸 사용해서 prediction하면됨\n",
        "        #print(len(new_data_list))\n",
        "        transformerdatalist=torch.stack(new_data_list,0)  #1,50,32\n",
        "        #print(transformerdatalist.shape)\n",
        "\n",
        "        my_output=encoder(transformerdatalist)\n",
        "        #print(my_output)\n",
        "        #print(my_output.shape) #1975,50,32\n",
        "        result_list=[]\n",
        "        for i in range(85):\n",
        "          for j in range(len(global_new_out)):\n",
        "            result_list.append(my_output[j][i])\n",
        "        #print(len(result_list))\n",
        "        #print(len(result_list[0]))\n",
        "        new_new_out=torch.stack(result_list,0)\n",
        "        #print(new_new_out.shape)\n",
        "        \n",
        "        out = self.fc(new_new_out)\n",
        "        \n",
        "        #input() \n",
        "        # out.size() --> 100, 10\n",
        "        return out\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c5dbpw7-s8lV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train)//85)\n",
        "print(len(x_val)//85)\n",
        "print(len(x_test)//85)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yX2o6EWtFlP",
        "outputId": "985e6917-5186-411e-dfbe-2386b7df9a57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "398\n",
            "42\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (name, param) in enumerate(model.named_parameters()):\n",
        "  print(idx, name, param.requires_grad)\n",
        "  print(model.parameters())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "0LiY_-cuDEWv",
        "outputId": "3449aabc-a0cd-453b-c0ab-3f996282497c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-075075f998c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "#####################\n",
        "num_epochs = 200\n",
        "hist = np.zeros(num_epochs)\n",
        "seq=10\n",
        "# Number of steps to unroll\n",
        "seq_dim =seq-1  \n",
        "beta=1\n",
        "patience=200\n",
        "check_early_stopping=0\n",
        "val_accuracy=0\n",
        "# Build model\n",
        "#####################\n",
        "\n",
        "#the window size𝑤 in {10, 15}, the market context weight\n",
        "# 𝛽 in {0.01, 0.1, 1}, the hidden layer size ℎ in {64, 128}, the number\n",
        "# of epochs in {100, 200}, and the learning rate in {0.001, 0.0001}. We\n",
        "# set the strength 𝜆 of selective regularization to 1 and the dropout\n",
        "# rate to 0.15. We use the Adam optimizer [14] for the training with\n",
        "# the early stopping by the validation accuracy. For competitors, we\n",
        "# use the default settings in their public implementations.\n",
        "input_dim = 11\n",
        "\n",
        "num_layers = 1 \n",
        "output_dim = 1\n",
        "stocknumbers=85 #stocknumbers acl 85. kdd 50\n",
        "n_heads=4\n",
        "\n",
        "dropout=0.15\n",
        "\n",
        "beta_dir=[1] #1\n",
        "hidden_list=[128 ] #128\n",
        "lr_list=[0.001] #0.0001\n",
        "\n",
        "result_dir={}\n",
        "\n",
        "for beta in beta_dir:\n",
        "  for hidden in hidden_list:\n",
        "    for learningrate in lr_list:\n",
        "      hidden_dim=hidden\n",
        "      pf_dim=hidden_dim * 4\n",
        "      encoder=Encoder(\n",
        "                 input_dim, \n",
        "                 hidden_dim, \n",
        "                 1, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device, \n",
        "                 \n",
        "                 max_length = 100)\n",
        "      model = DTML(input_dim=input_dim, hidden_dim=hidden, output_dim=output_dim, num_layers=num_layers,encoder=encoder).to(device)\n",
        "\n",
        "      loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "      optimiser = torch.optim.Adam(model.parameters(), lr=learningrate)\n",
        "      print(beta,hidden,learningrate)\n",
        "\n",
        "\n",
        "\n",
        "      for t in range(num_epochs):\n",
        "          # Initialise hidden state\n",
        "          # Don't do this if you want your LSTM to be stateful\n",
        "          #model.hidden = model.init_hidden()\n",
        "          model.train()\n",
        "          # Forward pass\n",
        "          y_train_pred = model(x_train,len(x_train)//85,global_train,beta)\n",
        "          # print(y_train_pred)\n",
        "          # print(y_train_pred.shape)\n",
        "          # print(y_train)\n",
        "          # print(y_train.shape)\n",
        "          print(\"traindata accuracy \",get_accuracy(y_train,y_train_pred))\n",
        "          loss = loss_fn(y_train_pred, y_train)\n",
        "          l2_lambda = 1\n",
        "          # l2_norm = sum(p.pow(2.0).sum()\n",
        "          #               for p in model.parameters())\n",
        "          # for idx, p in enumerate(model.parameters()):\n",
        "          #   if idx==34:\n",
        "          #     l2_norm = p.pow(2.0).sum()\n",
        "          # loss = loss + l2_lambda * l2_norm\n",
        "          #print(loss)\n",
        "          \n",
        "          if t % 10 == 0 and t !=0:\n",
        "              print(\"Epoch \", t, \"CE: \", loss.item())\n",
        "          hist[t] = loss.item()\n",
        "          print(loss)\n",
        "          # Zero out gradient, else they will accumulate between epochs\n",
        "          optimiser.zero_grad()\n",
        "\n",
        "          # Backward pass\n",
        "          loss.backward()\n",
        "\n",
        "          # Update parameters\n",
        "          optimiser.step()\n",
        "\n",
        "          model.eval()\n",
        "          correct=0\n",
        "          with torch.no_grad():\n",
        "            y_val_pred=model(x_val,len(x_val)//85,global_val,beta)\n",
        "            #print(y_val_pred)\n",
        "            print(get_accuracy(y_val,y_val_pred))\n",
        "            if val_accuracy <get_accuracy(y_val,y_val_pred):\n",
        "              val_accuracy=get_accuracy(y_val,y_val_pred)\n",
        "              check_early_stopping=0\n",
        "            else:\n",
        "              check_early_stopping=check_early_stopping+1\n",
        "          if check_early_stopping==patience:\n",
        "            print(\"early stopping!\")\n",
        "            print(val_accuracy)\n",
        "            print(\"epoch: \",t)\n",
        "            \n",
        "            break\n",
        "\n",
        "\n",
        "          #test score\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "              y_test_pred=model(x_test,len(x_test)//85,global_test,beta)\n",
        "              \n",
        "              print(\"testdata accuracy \",get_accuracy(y_test,y_test_pred))\n",
        "          result_dir[\"beta_{}_hidden_{}_lr_{}\".format(beta,hidden,learningrate)]=get_accuracy(y_test,y_test_pred)\n",
        "      torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4S3RJRQQtOb",
        "outputId": "497478b4-8d04-471f-9293-d728787cd261"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 128 0.001\n",
            "traindata accuracy  0.4904818208690511\n",
            "tensor(0.7008, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5091930239432456\n",
            "tensor(0.8961, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4591036414565826\n",
            "testdata accuracy  0.5029411764705882\n",
            "traindata accuracy  0.5091043452556903\n",
            "tensor(0.7203, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5470588235294118\n",
            "testdata accuracy  0.48878676470588234\n",
            "traindata accuracy  0.4923736328702335\n",
            "tensor(0.7191, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5406162464985994\n",
            "testdata accuracy  0.48455882352941176\n",
            "traindata accuracy  0.4911025716819391\n",
            "tensor(0.7670, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5406162464985994\n",
            "testdata accuracy  0.48455882352941176\n",
            "traindata accuracy  0.4907774164942359\n",
            "tensor(0.7478, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5414565826330532\n",
            "testdata accuracy  0.48474264705882353\n",
            "traindata accuracy  0.4914572864321608\n",
            "tensor(0.7093, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.48515406162464986\n",
            "testdata accuracy  0.4943014705882353\n",
            "traindata accuracy  0.5090452261306533\n",
            "tensor(0.6932, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5092817026308011\n",
            "tensor(0.7013, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5093408217558381\n",
            "tensor(0.7137, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5093408217558381\n",
            "Epoch  10 CE:  0.7181404829025269\n",
            "tensor(0.7181, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5092225835057641\n",
            "tensor(0.7126, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5092817026308011\n",
            "tensor(0.7031, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4613445378151261\n",
            "testdata accuracy  0.503125\n",
            "traindata accuracy  0.5101093703813183\n",
            "tensor(0.6953, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.47843137254901963\n",
            "testdata accuracy  0.5082720588235294\n",
            "traindata accuracy  0.514631983446645\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5392156862745098\n",
            "testdata accuracy  0.5007352941176471\n",
            "traindata accuracy  0.5012710611882945\n",
            "tensor(0.6949, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5481792717086835\n",
            "testdata accuracy  0.4933823529411765\n",
            "traindata accuracy  0.4940585279337866\n",
            "tensor(0.6987, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5417366946778711\n",
            "testdata accuracy  0.48823529411764705\n",
            "traindata accuracy  0.4919597989949749\n",
            "tensor(0.7017, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.542016806722689\n",
            "testdata accuracy  0.4904411764705882\n",
            "traindata accuracy  0.492403192432752\n",
            "tensor(0.7018, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5498599439775911\n",
            "testdata accuracy  0.49466911764705884\n",
            "traindata accuracy  0.49547738693467336\n",
            "tensor(0.6995, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5495798319327732\n",
            "testdata accuracy  0.5005514705882353\n",
            "traindata accuracy  0.49899497487437183\n",
            "Epoch  20 CE:  0.696520984172821\n",
            "tensor(0.6965, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5249299719887955\n",
            "testdata accuracy  0.5097426470588236\n",
            "traindata accuracy  0.5055867573159917\n",
            "tensor(0.6939, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.48207282913165267\n",
            "testdata accuracy  0.5102941176470588\n",
            "traindata accuracy  0.5129766479456104\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4658263305322129\n",
            "testdata accuracy  0.513235294117647\n",
            "traindata accuracy  0.5140999113213125\n",
            "tensor(0.6930, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45966386554621846\n",
            "testdata accuracy  0.502389705882353\n",
            "traindata accuracy  0.5112326337570204\n",
            "tensor(0.6940, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5099911321312445\n",
            "tensor(0.6955, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5097546556310967\n",
            "tensor(0.6960, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5094295004433934\n",
            "tensor(0.6958, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45854341736694676\n",
            "testdata accuracy  0.5033088235294118\n",
            "traindata accuracy  0.5104345255690216\n",
            "tensor(0.6949, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4588235294117647\n",
            "testdata accuracy  0.5036764705882353\n",
            "traindata accuracy  0.5104345255690216\n",
            "tensor(0.6937, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.45938375350140054\n",
            "testdata accuracy  0.509375\n",
            "traindata accuracy  0.5146615430091634\n",
            "Epoch  30 CE:  0.692971408367157\n",
            "tensor(0.6930, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4778711484593838\n",
            "testdata accuracy  0.509375\n",
            "traindata accuracy  0.5137747561336092\n",
            "tensor(0.6927, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5092436974789916\n",
            "testdata accuracy  0.5196691176470588\n",
            "traindata accuracy  0.5092225835057641\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5235294117647059\n",
            "testdata accuracy  0.5185661764705882\n",
            "traindata accuracy  0.5078924031924328\n",
            "tensor(0.6931, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5364145658263305\n",
            "testdata accuracy  0.5128676470588235\n",
            "traindata accuracy  0.5044930535028082\n",
            "tensor(0.6936, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5369747899159664\n",
            "testdata accuracy  0.5115808823529412\n",
            "traindata accuracy  0.5072125332545079\n",
            "tensor(0.6936, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5249299719887955\n",
            "testdata accuracy  0.5150735294117647\n",
            "traindata accuracy  0.5068282589417676\n",
            "tensor(0.6936, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5204481792717087\n",
            "testdata accuracy  0.5167279411764706\n",
            "traindata accuracy  0.5089861070056163\n",
            "tensor(0.6932, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5128851540616246\n",
            "testdata accuracy  0.5121323529411764\n",
            "traindata accuracy  0.5131835648832397\n",
            "tensor(0.6928, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.49299719887955185\n",
            "testdata accuracy  0.5154411764705882\n",
            "traindata accuracy  0.5133313626958321\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4781512605042017\n",
            "testdata accuracy  0.5126838235294118\n",
            "traindata accuracy  0.5172036653857522\n",
            "Epoch  40 CE:  0.6922356486320496\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.47366946778711483\n",
            "testdata accuracy  0.5073529411764706\n",
            "traindata accuracy  0.5132722435707952\n",
            "tensor(0.6927, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.46750700280112045\n",
            "testdata accuracy  0.5097426470588236\n",
            "traindata accuracy  0.514631983446645\n",
            "tensor(0.6927, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4624649859943978\n",
            "testdata accuracy  0.5121323529411764\n",
            "traindata accuracy  0.5145137451965711\n",
            "tensor(0.6927, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4624649859943978\n",
            "testdata accuracy  0.5125\n",
            "traindata accuracy  0.5115873485072421\n",
            "tensor(0.6928, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.46190476190476193\n",
            "testdata accuracy  0.5134191176470588\n",
            "traindata accuracy  0.5144250665090156\n",
            "tensor(0.6927, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4599439775910364\n",
            "testdata accuracy  0.5119485294117647\n",
            "traindata accuracy  0.5136565178835353\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4677871148459384\n",
            "testdata accuracy  0.5097426470588236\n",
            "traindata accuracy  0.5167898315104936\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4756302521008403\n",
            "testdata accuracy  0.5097426470588236\n",
            "traindata accuracy  0.5183564883239729\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.49131652661064423\n",
            "testdata accuracy  0.5158088235294118\n",
            "traindata accuracy  0.5182086905113804\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.503641456582633\n",
            "testdata accuracy  0.5213235294117647\n",
            "traindata accuracy  0.5167011528229383\n",
            "Epoch  50 CE:  0.6924234628677368\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5137254901960784\n",
            "testdata accuracy  0.5229779411764706\n",
            "traindata accuracy  0.5151049364469406\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5123249299719888\n",
            "testdata accuracy  0.5229779411764706\n",
            "traindata accuracy  0.5123854566952409\n",
            "tensor(0.6926, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5159663865546219\n",
            "testdata accuracy  0.521875\n",
            "traindata accuracy  0.5160508424475317\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.511204481792717\n",
            "testdata accuracy  0.5198529411764706\n",
            "traindata accuracy  0.5159621637599764\n",
            "tensor(0.6924, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.503641456582633\n",
            "testdata accuracy  0.5240808823529411\n",
            "traindata accuracy  0.5142477091339048\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.49327731092436977\n",
            "testdata accuracy  0.5211397058823529\n",
            "traindata accuracy  0.518120011823825\n",
            "tensor(0.6921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.48095238095238096\n",
            "testdata accuracy  0.5169117647058824\n",
            "traindata accuracy  0.5156961276973101\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.47675070028011207\n",
            "testdata accuracy  0.5126838235294118\n",
            "traindata accuracy  0.5157848063848655\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4764705882352941\n",
            "testdata accuracy  0.5091911764705882\n",
            "traindata accuracy  0.5168489506355306\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.47675070028011207\n",
            "testdata accuracy  0.5110294117647058\n",
            "traindata accuracy  0.5139225539462016\n",
            "Epoch  60 CE:  0.6924912333488464\n",
            "tensor(0.6925, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4722689075630252\n",
            "testdata accuracy  0.5110294117647058\n",
            "traindata accuracy  0.5191841560744901\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.47282913165266105\n",
            "testdata accuracy  0.5119485294117647\n",
            "traindata accuracy  0.5197753473248596\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.47843137254901963\n",
            "testdata accuracy  0.5125\n",
            "traindata accuracy  0.5158734850724209\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4854341736694678\n",
            "testdata accuracy  0.5121323529411764\n",
            "traindata accuracy  0.518740762636713\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4935574229691877\n",
            "testdata accuracy  0.5148897058823529\n",
            "traindata accuracy  0.5166420336979013\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4943977591036415\n",
            "testdata accuracy  0.5216911764705883\n",
            "traindata accuracy  0.517499261010937\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4980392156862745\n",
            "testdata accuracy  0.5257352941176471\n",
            "traindata accuracy  0.5188590008867868\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5033613445378151\n",
            "testdata accuracy  0.5262867647058823\n",
            "traindata accuracy  0.5206916937629323\n",
            "tensor(0.6921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5033613445378151\n",
            "testdata accuracy  0.5259191176470588\n",
            "traindata accuracy  0.5190659178244162\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5025210084033613\n",
            "testdata accuracy  0.5261029411764706\n",
            "traindata accuracy  0.5196571090747857\n",
            "Epoch  70 CE:  0.6920121908187866\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4980392156862745\n",
            "testdata accuracy  0.5244485294117647\n",
            "traindata accuracy  0.518681643511676\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4969187675070028\n",
            "testdata accuracy  0.5207720588235294\n",
            "traindata accuracy  0.5182678096364174\n",
            "tensor(0.6921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4946778711484594\n",
            "testdata accuracy  0.5172794117647059\n",
            "traindata accuracy  0.5183564883239729\n",
            "tensor(0.6921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.49299719887955185\n",
            "testdata accuracy  0.5148897058823529\n",
            "traindata accuracy  0.5178539757611588\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.492156862745098\n",
            "testdata accuracy  0.5147058823529411\n",
            "traindata accuracy  0.5173219036358262\n",
            "tensor(0.6923, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.48935574229691875\n",
            "testdata accuracy  0.5139705882352941\n",
            "traindata accuracy  0.5192137156370086\n",
            "tensor(0.6922, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4918767507002801\n",
            "testdata accuracy  0.5148897058823529\n",
            "traindata accuracy  0.5176766183860478\n",
            "tensor(0.6921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4927170868347339\n",
            "testdata accuracy  0.5148897058823529\n",
            "traindata accuracy  0.5193615134496009\n",
            "tensor(0.6921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4946778711484594\n",
            "testdata accuracy  0.5172794117647059\n",
            "traindata accuracy  0.5206916937629323\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4943977591036415\n",
            "testdata accuracy  0.5185661764705882\n",
            "traindata accuracy  0.5196275495122672\n",
            "Epoch  80 CE:  0.6918760538101196\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.492436974789916\n",
            "testdata accuracy  0.518014705882353\n",
            "traindata accuracy  0.5207508128879692\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4977591036414566\n",
            "testdata accuracy  0.5205882352941177\n",
            "traindata accuracy  0.5195979899497487\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5008403361344538\n",
            "testdata accuracy  0.5227941176470589\n",
            "traindata accuracy  0.5211350872007094\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5002801120448179\n",
            "testdata accuracy  0.5238970588235294\n",
            "traindata accuracy  0.5205438959503399\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5005602240896359\n",
            "testdata accuracy  0.5224264705882353\n",
            "traindata accuracy  0.5200413833875258\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5008403361344538\n",
            "testdata accuracy  0.5211397058823529\n",
            "traindata accuracy  0.5203665385752291\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4991596638655462\n",
            "testdata accuracy  0.5200367647058823\n",
            "traindata accuracy  0.5175879396984925\n",
            "tensor(0.6921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.49831932773109244\n",
            "testdata accuracy  0.5196691176470588\n",
            "traindata accuracy  0.518681643511676\n",
            "tensor(0.6921, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4966386554621849\n",
            "testdata accuracy  0.5189338235294118\n",
            "traindata accuracy  0.5214602423884126\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.49719887955182074\n",
            "testdata accuracy  0.5183823529411765\n",
            "traindata accuracy  0.5246231155778894\n",
            "Epoch  90 CE:  0.6919020414352417\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.49747899159663866\n",
            "testdata accuracy  0.5169117647058824\n",
            "traindata accuracy  0.5192432751995271\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4977591036414566\n",
            "testdata accuracy  0.5169117647058824\n",
            "traindata accuracy  0.5201596216375998\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4980392156862745\n",
            "testdata accuracy  0.5163602941176471\n",
            "traindata accuracy  0.5255690215784806\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4997198879551821\n",
            "testdata accuracy  0.5189338235294118\n",
            "traindata accuracy  0.519804906887378\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5025210084033613\n",
            "testdata accuracy  0.5196691176470588\n",
            "traindata accuracy  0.5244753177652971\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5019607843137255\n",
            "testdata accuracy  0.5222426470588235\n",
            "traindata accuracy  0.5195979899497487\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5044817927170868\n",
            "testdata accuracy  0.5213235294117647\n",
            "traindata accuracy  0.5222583505764115\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.503641456582633\n",
            "testdata accuracy  0.5215073529411764\n",
            "traindata accuracy  0.5210168489506355\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5042016806722689\n",
            "testdata accuracy  0.5222426470588235\n",
            "traindata accuracy  0.522731303576707\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5044817927170868\n",
            "testdata accuracy  0.5209558823529412\n",
            "traindata accuracy  0.5212533254507833\n",
            "Epoch  100 CE:  0.6918438673019409\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5047619047619047\n",
            "testdata accuracy  0.5205882352941177\n",
            "traindata accuracy  0.5214602423884126\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5044817927170868\n",
            "testdata accuracy  0.5209558823529412\n",
            "traindata accuracy  0.520425657700266\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5016806722689076\n",
            "testdata accuracy  0.5191176470588236\n",
            "traindata accuracy  0.51879988176175\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5\n",
            "testdata accuracy  0.5185661764705882\n",
            "traindata accuracy  0.5214306828258942\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.4997198879551821\n",
            "testdata accuracy  0.5183823529411765\n",
            "traindata accuracy  0.5242684008276678\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5033613445378151\n",
            "testdata accuracy  0.5193014705882353\n",
            "traindata accuracy  0.5216375997635235\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5064425770308123\n",
            "testdata accuracy  0.51875\n",
            "traindata accuracy  0.5212828850133018\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5061624649859944\n",
            "testdata accuracy  0.5193014705882353\n",
            "traindata accuracy  0.5230268992018918\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5047619047619047\n",
            "testdata accuracy  0.5220588235294118\n",
            "traindata accuracy  0.5234998522021874\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5070028011204482\n",
            "testdata accuracy  0.5222426470588235\n",
            "traindata accuracy  0.5184451670115282\n",
            "Epoch  110 CE:  0.6919191479682922\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5070028011204482\n",
            "testdata accuracy  0.5227941176470589\n",
            "traindata accuracy  0.5196866686373042\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5078431372549019\n",
            "testdata accuracy  0.5237132352941176\n",
            "traindata accuracy  0.5211646467632279\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5081232492997199\n",
            "testdata accuracy  0.5237132352941176\n",
            "traindata accuracy  0.5233224948270766\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.507563025210084\n",
            "testdata accuracy  0.5240808823529411\n",
            "traindata accuracy  0.5237658882648537\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5070028011204482\n",
            "testdata accuracy  0.5229779411764706\n",
            "traindata accuracy  0.5180017735737511\n",
            "tensor(0.6920, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5070028011204482\n",
            "testdata accuracy  0.5246323529411765\n",
            "traindata accuracy  0.5211942063257464\n",
            "tensor(0.6919, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5072829131652661\n",
            "testdata accuracy  0.5244485294117647\n",
            "traindata accuracy  0.5240023647650015\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5072829131652661\n",
            "testdata accuracy  0.5244485294117647\n",
            "traindata accuracy  0.5237954478273722\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5078431372549019\n",
            "testdata accuracy  0.5244485294117647\n",
            "traindata accuracy  0.5223765888264854\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5067226890756302\n",
            "testdata accuracy  0.5227941176470589\n",
            "traindata accuracy  0.5233224948270766\n",
            "Epoch  120 CE:  0.6916900277137756\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5086834733893557\n",
            "testdata accuracy  0.5227941176470589\n",
            "traindata accuracy  0.5210759680756725\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5086834733893557\n",
            "testdata accuracy  0.5240808823529411\n",
            "traindata accuracy  0.5229382205143364\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5072829131652661\n",
            "testdata accuracy  0.5237132352941176\n",
            "traindata accuracy  0.5212828850133018\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.511204481792717\n",
            "testdata accuracy  0.5237132352941176\n",
            "traindata accuracy  0.5215784806384866\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5126050420168067\n",
            "testdata accuracy  0.5246323529411765\n",
            "traindata accuracy  0.520987289388117\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5106442577030812\n",
            "testdata accuracy  0.5244485294117647\n",
            "traindata accuracy  0.5221105527638191\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5109243697478991\n",
            "testdata accuracy  0.5238970588235294\n",
            "traindata accuracy  0.5234407330771504\n",
            "tensor(0.6918, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.511204481792717\n",
            "testdata accuracy  0.524264705882353\n",
            "traindata accuracy  0.5201891812001183\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5109243697478991\n",
            "testdata accuracy  0.5237132352941176\n",
            "traindata accuracy  0.5253916642033698\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.511204481792717\n",
            "testdata accuracy  0.5240808823529411\n",
            "traindata accuracy  0.522731303576707\n",
            "Epoch  130 CE:  0.6915628910064697\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5117647058823529\n",
            "testdata accuracy  0.5229779411764706\n",
            "traindata accuracy  0.5221992314513745\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.511204481792717\n",
            "testdata accuracy  0.5224264705882353\n",
            "traindata accuracy  0.522731303576707\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5117647058823529\n",
            "testdata accuracy  0.5229779411764706\n",
            "traindata accuracy  0.5253029855158143\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5142857142857142\n",
            "testdata accuracy  0.5220588235294118\n",
            "traindata accuracy  0.5228791013892994\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5134453781512605\n",
            "testdata accuracy  0.5235294117647059\n",
            "traindata accuracy  0.52228791013893\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5123249299719888\n",
            "testdata accuracy  0.5251838235294117\n",
            "traindata accuracy  0.5215784806384866\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5126050420168067\n",
            "testdata accuracy  0.5240808823529411\n",
            "traindata accuracy  0.5237363287023352\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5134453781512605\n",
            "testdata accuracy  0.5237132352941176\n",
            "traindata accuracy  0.5219036358261898\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5145658263305322\n",
            "testdata accuracy  0.5220588235294118\n",
            "traindata accuracy  0.5206325746378954\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.515126050420168\n",
            "testdata accuracy  0.5220588235294118\n",
            "traindata accuracy  0.5236772095772982\n",
            "Epoch  140 CE:  0.6915952563285828\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.515686274509804\n",
            "testdata accuracy  0.5229779411764706\n",
            "traindata accuracy  0.523913686077446\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5165266106442578\n",
            "testdata accuracy  0.5246323529411765\n",
            "traindata accuracy  0.5224948270765593\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5182072829131653\n",
            "testdata accuracy  0.5248161764705882\n",
            "traindata accuracy  0.5278746674549216\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5198879551820729\n",
            "testdata accuracy  0.5248161764705882\n",
            "traindata accuracy  0.5240023647650015\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5201680672268908\n",
            "testdata accuracy  0.5257352941176471\n",
            "traindata accuracy  0.5228199822642625\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5196078431372549\n",
            "testdata accuracy  0.5270220588235294\n",
            "traindata accuracy  0.5240614838900385\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5201680672268908\n",
            "testdata accuracy  0.5257352941176471\n",
            "traindata accuracy  0.5257463789535914\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5190476190476191\n",
            "testdata accuracy  0.5246323529411765\n",
            "traindata accuracy  0.5207212533254508\n",
            "tensor(0.6917, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5176470588235295\n",
            "testdata accuracy  0.5235294117647059\n",
            "traindata accuracy  0.5230564587644103\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5176470588235295\n",
            "testdata accuracy  0.5248161764705882\n",
            "traindata accuracy  0.5240023647650015\n",
            "Epoch  150 CE:  0.6914750933647156\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5187675070028012\n",
            "testdata accuracy  0.5244485294117647\n",
            "traindata accuracy  0.5253029855158143\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.519327731092437\n",
            "testdata accuracy  0.525\n",
            "traindata accuracy  0.5224357079515223\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.519327731092437\n",
            "testdata accuracy  0.5253676470588236\n",
            "traindata accuracy  0.5217558380135974\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5187675070028012\n",
            "testdata accuracy  0.5237132352941176\n",
            "traindata accuracy  0.5234702926396689\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5184873949579832\n",
            "testdata accuracy  0.5246323529411765\n",
            "traindata accuracy  0.523972805202483\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5187675070028012\n",
            "testdata accuracy  0.5231617647058824\n",
            "traindata accuracy  0.5224948270765593\n",
            "tensor(0.6916, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.519327731092437\n",
            "testdata accuracy  0.522610294117647\n",
            "traindata accuracy  0.5225835057641147\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5182072829131653\n",
            "testdata accuracy  0.5235294117647059\n",
            "traindata accuracy  0.5251847472657405\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5184873949579832\n",
            "testdata accuracy  0.5253676470588236\n",
            "traindata accuracy  0.5238545669524091\n",
            "tensor(0.6915, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5201680672268908\n",
            "testdata accuracy  0.5270220588235294\n",
            "traindata accuracy  0.5253029855158143\n",
            "Epoch  160 CE:  0.6913396716117859\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5215686274509804\n",
            "testdata accuracy  0.5268382352941177\n",
            "traindata accuracy  0.5243866390777416\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5204481792717087\n",
            "testdata accuracy  0.5268382352941177\n",
            "traindata accuracy  0.5287318947679575\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5204481792717087\n",
            "testdata accuracy  0.5253676470588236\n",
            "traindata accuracy  0.5264262488915165\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5218487394957984\n",
            "testdata accuracy  0.5255514705882353\n",
            "traindata accuracy  0.5246231155778894\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.523249299719888\n",
            "testdata accuracy  0.5244485294117647\n",
            "traindata accuracy  0.5255099024534436\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5235294117647059\n",
            "testdata accuracy  0.5244485294117647\n",
            "traindata accuracy  0.5252438663907775\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5229691876750701\n",
            "testdata accuracy  0.525\n",
            "traindata accuracy  0.5246526751404079\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5210084033613446\n",
            "testdata accuracy  0.5253676470588236\n",
            "traindata accuracy  0.5277859887673663\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5184873949579832\n",
            "testdata accuracy  0.5261029411764706\n",
            "traindata accuracy  0.5235294117647059\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5198879551820729\n",
            "testdata accuracy  0.5272058823529412\n",
            "traindata accuracy  0.5258646172036654\n",
            "Epoch  170 CE:  0.691274881362915\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5196078431372549\n",
            "testdata accuracy  0.5261029411764706\n",
            "traindata accuracy  0.5226130653266332\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5215686274509804\n",
            "testdata accuracy  0.525\n",
            "traindata accuracy  0.5268105232042566\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5210084033613446\n",
            "testdata accuracy  0.5259191176470588\n",
            "traindata accuracy  0.5238841265149276\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5210084033613446\n",
            "testdata accuracy  0.5253676470588236\n",
            "traindata accuracy  0.5247413538279634\n",
            "tensor(0.6914, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5218487394957984\n",
            "testdata accuracy  0.5266544117647058\n",
            "traindata accuracy  0.5246231155778894\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5224089635854342\n",
            "testdata accuracy  0.5262867647058823\n",
            "traindata accuracy  0.5246822347029264\n",
            "tensor(0.6913, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5238095238095238\n",
            "testdata accuracy  0.5270220588235294\n",
            "traindata accuracy  0.5268696423292936\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5252100840336135\n",
            "testdata accuracy  0.5275735294117647\n",
            "traindata accuracy  0.5268400827667751\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5260504201680672\n",
            "testdata accuracy  0.528860294117647\n",
            "traindata accuracy  0.5247117942654449\n",
            "tensor(0.6911, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5254901960784314\n",
            "testdata accuracy  0.5295955882352941\n",
            "traindata accuracy  0.5268400827667751\n",
            "Epoch  180 CE:  0.6911553144454956\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5252100840336135\n",
            "testdata accuracy  0.5292279411764705\n",
            "traindata accuracy  0.5252438663907775\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5252100840336135\n",
            "testdata accuracy  0.5279411764705882\n",
            "traindata accuracy  0.5260715341412947\n",
            "tensor(0.6910, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5240896358543418\n",
            "testdata accuracy  0.5275735294117647\n",
            "traindata accuracy  0.5257168193910731\n",
            "tensor(0.6911, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5243697478991597\n",
            "testdata accuracy  0.5273897058823529\n",
            "traindata accuracy  0.5252734259532958\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5240896358543418\n",
            "testdata accuracy  0.5279411764705882\n",
            "traindata accuracy  0.5276973100798108\n",
            "tensor(0.6911, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5238095238095238\n",
            "testdata accuracy  0.5292279411764705\n",
            "traindata accuracy  0.5231746970144842\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5260504201680672\n",
            "testdata accuracy  0.5301470588235294\n",
            "traindata accuracy  0.5245639964528525\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.527170868347339\n",
            "testdata accuracy  0.53125\n",
            "traindata accuracy  0.5252438663907775\n",
            "tensor(0.6911, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5285714285714286\n",
            "testdata accuracy  0.5314338235294118\n",
            "traindata accuracy  0.5271947975169967\n",
            "tensor(0.6911, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5291316526610644\n",
            "testdata accuracy  0.5314338235294118\n",
            "traindata accuracy  0.5259828554537392\n",
            "Epoch  190 CE:  0.6911438703536987\n",
            "tensor(0.6911, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5285714285714286\n",
            "testdata accuracy  0.5310661764705882\n",
            "traindata accuracy  0.5273721548921076\n",
            "tensor(0.6909, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5274509803921569\n",
            "testdata accuracy  0.5303308823529411\n",
            "traindata accuracy  0.5255394620159621\n",
            "tensor(0.6912, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5280112044817927\n",
            "testdata accuracy  0.5308823529411765\n",
            "traindata accuracy  0.5248595920780372\n",
            "tensor(0.6909, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5274509803921569\n",
            "testdata accuracy  0.5308823529411765\n",
            "traindata accuracy  0.5273721548921076\n",
            "tensor(0.6910, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5291316526610644\n",
            "testdata accuracy  0.5310661764705882\n",
            "traindata accuracy  0.5284067395802542\n",
            "tensor(0.6909, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5288515406162465\n",
            "testdata accuracy  0.5319852941176471\n",
            "traindata accuracy  0.5281998226426249\n",
            "tensor(0.6909, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5288515406162465\n",
            "testdata accuracy  0.5332720588235295\n",
            "traindata accuracy  0.5245935560153709\n",
            "tensor(0.6911, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.527170868347339\n",
            "testdata accuracy  0.5325367647058824\n",
            "traindata accuracy  0.5276973100798108\n",
            "tensor(0.6910, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5282913165266107\n",
            "testdata accuracy  0.5330882352941176\n",
            "traindata accuracy  0.528643216080402\n",
            "tensor(0.6909, device='cuda:0',\n",
            "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "0.5291316526610644\n",
            "testdata accuracy  0.5299632352941176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmeo0f12VCIv",
        "outputId": "7b9ae417-3bf6-4f86-b17b-8a11b77b14b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'beta_0.01_hidden_64_lr_0.001': 0.4988888888888889, 'beta_0.01_hidden_64_lr_0.0001': 0.5177777777777778, 'beta_0.01_hidden_128_lr_0.001': 0.49476190476190474, 'beta_0.01_hidden_128_lr_0.0001': 0.5284126984126984, 'beta_0.1_hidden_64_lr_0.001': 0.5308730158730158, 'beta_0.1_hidden_64_lr_0.0001': 0.4942857142857143, 'beta_0.1_hidden_128_lr_0.001': 0.5073809523809524, 'beta_0.1_hidden_128_lr_0.0001': 0.5273015873015873, 'beta_1_hidden_64_lr_0.001': 0.5311111111111111, 'beta_1_hidden_64_lr_0.0001': 0.5307142857142857, 'beta_1_hidden_128_lr_0.001': 0.5311904761904762, 'beta_1_hidden_128_lr_0.0001': 0.5053968253968254}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist, label=\"Training loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "4OeV0crXBEfv",
        "outputId": "c8cf3c6f-fa00-4d0a-f263-b596eb6eccaf"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.LongTensor([0.2234])\n",
        "y = torch.LongTensor([1])\n",
        "print(torch.nn.CrossEntropyLoss(x,y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs4OYWCAE98S",
        "outputId": "cd84b727-c642-467f-e942-9b85db223b5b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CrossEntropyLoss()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(y_train_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_F2liekBKfu",
        "outputId": "aa43ba5a-e8ec-4f8f-84a2-1ca25eb52ff8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([98750, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd jolproject/Adv-ALSTM/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYV2DC7mMCSO",
        "outputId": "5b83c4a0-33c0-4b92-b770-36b4293c7d60"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/jolproject/Adv-ALSTM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "fnames = [fname for fname in os.listdir(\"./data/stocknet-dataset/price/ourpped\") if\n",
        "              os.path.isfile(os.path.join(\"./data/stocknet-dataset/price/ourpped\", fname))]\n",
        "\n",
        "\n",
        "# fnames = [fname for fname in os.listdir(\"./data/kdd17/ourpped/\") if\n",
        "#                os.path.isfile(os.path.join(\"./data/kdd17/ourpped/\", fname))]\n",
        "\n",
        "\n",
        "print(len(fnames))\n",
        "\n",
        "for fname in fnames:\n",
        "  temp = \"./data/stocknet-dataset/price/ourpped/\" + fname\n",
        "  data = pd.read_csv(temp)\n",
        "  print(fname,len(data))\n",
        "  # for i in range(len(data)-1):\n",
        "  #   if data.iloc[i,3]>0:\n",
        "  #     data.iloc[i,11]=1\n",
        "  #   else:\n",
        "  #     data.iloc[i,11]=0\n",
        "  \n",
        "  \n",
        "  #data.to_csv(temp,index = False)\n",
        "  "
      ],
      "metadata": {
        "id": "dUgvrl-xDGx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83fb6378-3696-4c1e-91f6-96c080d1fa3c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87\n",
            "AAPL.csv 651\n",
            "ABB.csv 651\n",
            "ABBV.csv 651\n",
            "AEP.csv 651\n",
            "AGFS.csv 651\n",
            "AMGN.csv 651\n",
            "AMZN.csv 651\n",
            "BA.csv 651\n",
            "BABA.csv 651\n",
            "BAC.csv 651\n",
            "BBL.csv 651\n",
            "BCH.csv 651\n",
            "BHP.csv 651\n",
            "BP.csv 651\n",
            "BRK-A.csv 651\n",
            "BSAC.csv 651\n",
            "BUD.csv 651\n",
            "C.csv 651\n",
            "CAT.csv 651\n",
            "CELG.csv 651\n",
            "CHL.csv 651\n",
            "CHTR.csv 651\n",
            "CMCSA.csv 651\n",
            "CODI.csv 651\n",
            "CSCO.csv 651\n",
            "CVX.csv 651\n",
            "D.csv 651\n",
            "DHR.csv 651\n",
            "DIS.csv 651\n",
            "DUK.csv 651\n",
            "EXC.csv 651\n",
            "FB.csv 651\n",
            "GD.csv 651\n",
            "GE.csv 651\n",
            "GOOG.csv 651\n",
            "HD.csv 651\n",
            "HON.csv 651\n",
            "HRG.csv 651\n",
            "HSBC.csv 651\n",
            "IEP.csv 651\n",
            "INTC.csv 651\n",
            "JNJ.csv 651\n",
            "JPM.csv 651\n",
            "KO.csv 651\n",
            "LMT.csv 651\n",
            "MA.csv 651\n",
            "MCD.csv 651\n",
            "MDT.csv 651\n",
            "MMM.csv 651\n",
            "MO.csv 651\n",
            "MRK.csv 651\n",
            "MSFT.csv 651\n",
            "NEE.csv 651\n",
            "NGG.csv 651\n",
            "NVS.csv 651\n",
            "ORCL.csv 651\n",
            "PCG.csv 651\n",
            "PCLN.csv 651\n",
            "PEP.csv 651\n",
            "PFE.csv 651\n",
            "PG.csv 651\n",
            "PICO.csv 651\n",
            "PM.csv 651\n",
            "PPL.csv 651\n",
            "PTR.csv 651\n",
            "RDS-B.csv 651\n",
            "REX.csv 651\n",
            "SLB.csv 651\n",
            "SNP.csv 651\n",
            "SNY.csv 651\n",
            "SO.csv 651\n",
            "SPLP.csv 651\n",
            "SRE.csv 651\n",
            "T.csv 651\n",
            "TM.csv 651\n",
            "TOT.csv 651\n",
            "TSM.csv 651\n",
            "UL.csv 651\n",
            "UN.csv 651\n",
            "UNH.csv 651\n",
            "UPS.csv 651\n",
            "UTX.csv 651\n",
            "V.csv 651\n",
            "VZ.csv 651\n",
            "WFC.csv 651\n",
            "WMT.csv 651\n",
            "XOM.csv 651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=set()\n",
        "for i in range(len(data)):\n",
        "  t.add(data.iloc[i][11])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnNdOsdBF6Q0",
        "outputId": "a7e59959-2c85-4c96-89f6-66337703677c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0.0, 1.0, -123321.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=set()\n",
        "for fname in fnames:\n",
        "  temp = \"./data/kdd17/ourpped/\" + fname\n",
        "  print(temp)\n",
        "  data = pd.read_csv(temp,index_col=0)\n",
        "  print(data)\n",
        "  print(data.iloc[:,11])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAexHLFUjG_W",
        "outputId": "e79299fd-eb30-4869-916b-8fa8f8d4f2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/kdd17/ourpped/AAPL.csv\n",
            "            -123321.000000  -123321.000000.1  -123321.000000.2  \\\n",
            "Unnamed: 0                                                       \n",
            "0           -123321.000000    -123321.000000    -123321.000000   \n",
            "1           -123321.000000    -123321.000000    -123321.000000   \n",
            "2           -123321.000000    -123321.000000    -123321.000000   \n",
            "3           -123321.000000    -123321.000000    -123321.000000   \n",
            "4           -123321.000000    -123321.000000    -123321.000000   \n",
            "...                    ...               ...               ...   \n",
            "2512             -0.798147          0.000000         -0.798147   \n",
            "2513             -0.631080          0.460516         -0.656664   \n",
            "2514              0.650904          1.079132         -0.479621   \n",
            "2515             -0.239875          0.325536         -0.282705   \n",
            "2516              0.716631          1.191501         -0.336729   \n",
            "\n",
            "            -123321.000000.3  -123321.000000.4  -123321.000000.5  \\\n",
            "Unnamed: 0                                                         \n",
            "0             -123321.000000    -123321.000000    -123321.000000   \n",
            "1             -123321.000000    -123321.000000    -123321.000000   \n",
            "2             -123321.000000    -123321.000000    -123321.000000   \n",
            "3             -123321.000000    -123321.000000    -123321.000000   \n",
            "4             -123321.000000    -123321.000000    -123321.000000   \n",
            "...                      ...               ...               ...   \n",
            "2512                0.197778          0.197778          0.147615   \n",
            "2513                0.635088          0.635088         -0.378648   \n",
            "2514               -0.426403         -0.426403          0.015415   \n",
            "2515               -0.025693         -0.025693         -0.015422   \n",
            "2516               -0.779579         -0.779579          0.689001   \n",
            "\n",
            "            -123321.000000.6  -123321.000000.7  -123321.000000.8  \\\n",
            "Unnamed: 0                                                         \n",
            "0             -123321.000000    -123321.000000    -123321.000000   \n",
            "1             -123321.000000    -123321.000000    -123321.000000   \n",
            "2             -123321.000000    -123321.000000    -123321.000000   \n",
            "3             -123321.000000    -123321.000000    -123321.000000   \n",
            "4             -123321.000000    -123321.000000    -123321.000000   \n",
            "...                      ...               ...               ...   \n",
            "2512               -0.538102         -1.871493         -2.676362   \n",
            "2513               -0.828076         -2.027405         -3.047930   \n",
            "2514               -0.268930         -1.219026         -2.405791   \n",
            "2515               -0.111371         -0.868102         -2.114712   \n",
            "2516                0.673459          0.123755         -1.072353   \n",
            "\n",
            "            -123321.000000.9  -123321.000000.10  -123321.000000.11  \\\n",
            "Unnamed: 0                                                           \n",
            "0             -123321.000000     -123321.000000          -123321.0   \n",
            "1             -123321.000000     -123321.000000          -123321.0   \n",
            "2             -123321.000000     -123321.000000          -123321.0   \n",
            "3             -123321.000000     -123321.000000          -123321.0   \n",
            "4             -123321.000000     -123321.000000          -123321.0   \n",
            "...                      ...                ...                ...   \n",
            "2512               -3.033296          -3.712379                1.0   \n",
            "2513               -3.399626          -4.069022                1.0   \n",
            "2514               -2.813636          -3.342756                0.0   \n",
            "2515               -2.619723          -3.043208                0.0   \n",
            "2516               -1.696080          -2.113624                0.0   \n",
            "\n",
            "            -123321.000000.12  \n",
            "Unnamed: 0                     \n",
            "0              -123321.000000  \n",
            "1              -123321.000000  \n",
            "2              -123321.000000  \n",
            "3              -123321.000000  \n",
            "4              -123321.000000  \n",
            "...                       ...  \n",
            "2512               116.519997  \n",
            "2513               117.260002  \n",
            "2514               116.760002  \n",
            "2515               116.730003  \n",
            "2516               115.820000  \n",
            "\n",
            "[2517 rows x 13 columns]\n",
            "Unnamed: 0\n",
            "0      -123321.0\n",
            "1      -123321.0\n",
            "2      -123321.0\n",
            "3      -123321.0\n",
            "4      -123321.0\n",
            "          ...   \n",
            "2512         1.0\n",
            "2513         1.0\n",
            "2514         0.0\n",
            "2515         0.0\n",
            "2516         0.0\n",
            "Name: -123321.000000.11, Length: 2517, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if 'acl18' in args.path:\n",
        "#         tra_date = '2014-01-02'\n",
        "#         val_date = '2015-08-03'\n",
        "#         tes_date = '2015-10-01'\n",
        "#     elif 'kdd17' in args.path:\n",
        "#         tra_date = '2007-01-03'\n",
        "#         val_date = '2015-01-02'\n",
        "#         tes_date = '2016-01-04'\n",
        "\n",
        "#s&p 500 데이터 추출\n",
        "# tra_date = '2007-01-03'\n",
        "# val_date = '2015-01-02'\n",
        "# tes_date = '2016-01-04'\n",
        "\n",
        "\n",
        "tra_date = '2014-01-02'\n",
        "val_date = '2015-08-03'\n",
        "tes_date = '2015-10-01'\n",
        "#end date 2016-12-31\n",
        "import pandas_datareader.data as web\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "sp500 = web.DataReader('^GSPC', data_source='yahoo', start='6/3/2013', end='12/31/2015')"
      ],
      "metadata": {
        "id": "h_ZgT_-BkTFi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp500.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyJVE-WxCkv3",
        "outputId": "721d5338-fb50-4b18-b0f0-0b0ed08261d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 504 entries, 2014-01-02 to 2015-12-31\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   High       504 non-null    float64\n",
            " 1   Low        504 non-null    float64\n",
            " 2   Open       504 non-null    float64\n",
            " 3   Close      504 non-null    float64\n",
            " 4   Volume     504 non-null    int64  \n",
            " 5   Adj Close  504 non-null    float64\n",
            "dtypes: float64(5), int64(1)\n",
            "memory usage: 27.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "-9lS2cKwDEJu",
        "outputId": "bcfd37e5-7564-423a-d701-5f6a4ba16aed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   High          Low         Open        Close      Volume  \\\n",
              "Date                                                                         \n",
              "2013-06-03  1640.420044  1622.719971  1631.709961  1640.420044  3952070000   \n",
              "2013-06-04  1646.530029  1623.619995  1640.729980  1631.380005  3653840000   \n",
              "2013-06-05  1629.310059  1607.089966  1629.050049  1608.900024  3632350000   \n",
              "2013-06-06  1622.560059  1598.229980  1609.290039  1622.560059  3547380000   \n",
              "2013-06-07  1644.400024  1625.270020  1625.270020  1643.380005  3371990000   \n",
              "...                 ...          ...          ...          ...         ...   \n",
              "2015-12-24  2067.360107  2058.729980  2063.520020  2060.989990  1411860000   \n",
              "2015-12-28  2057.770020  2044.199951  2057.770020  2056.500000  2492510000   \n",
              "2015-12-29  2081.560059  2060.540039  2060.540039  2078.360107  2542000000   \n",
              "2015-12-30  2077.340088  2061.969971  2077.340088  2063.360107  2367430000   \n",
              "2015-12-31  2062.540039  2043.619995  2060.590088  2043.939941  2655330000   \n",
              "\n",
              "              Adj Close  \n",
              "Date                     \n",
              "2013-06-03  1640.420044  \n",
              "2013-06-04  1631.380005  \n",
              "2013-06-05  1608.900024  \n",
              "2013-06-06  1622.560059  \n",
              "2013-06-07  1643.380005  \n",
              "...                 ...  \n",
              "2015-12-24  2060.989990  \n",
              "2015-12-28  2056.500000  \n",
              "2015-12-29  2078.360107  \n",
              "2015-12-30  2063.360107  \n",
              "2015-12-31  2043.939941  \n",
              "\n",
              "[652 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ff54016-34c6-4014-aa34-7b9fb2f702d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-06-03</th>\n",
              "      <td>1640.420044</td>\n",
              "      <td>1622.719971</td>\n",
              "      <td>1631.709961</td>\n",
              "      <td>1640.420044</td>\n",
              "      <td>3952070000</td>\n",
              "      <td>1640.420044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-06-04</th>\n",
              "      <td>1646.530029</td>\n",
              "      <td>1623.619995</td>\n",
              "      <td>1640.729980</td>\n",
              "      <td>1631.380005</td>\n",
              "      <td>3653840000</td>\n",
              "      <td>1631.380005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-06-05</th>\n",
              "      <td>1629.310059</td>\n",
              "      <td>1607.089966</td>\n",
              "      <td>1629.050049</td>\n",
              "      <td>1608.900024</td>\n",
              "      <td>3632350000</td>\n",
              "      <td>1608.900024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-06-06</th>\n",
              "      <td>1622.560059</td>\n",
              "      <td>1598.229980</td>\n",
              "      <td>1609.290039</td>\n",
              "      <td>1622.560059</td>\n",
              "      <td>3547380000</td>\n",
              "      <td>1622.560059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-06-07</th>\n",
              "      <td>1644.400024</td>\n",
              "      <td>1625.270020</td>\n",
              "      <td>1625.270020</td>\n",
              "      <td>1643.380005</td>\n",
              "      <td>3371990000</td>\n",
              "      <td>1643.380005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-24</th>\n",
              "      <td>2067.360107</td>\n",
              "      <td>2058.729980</td>\n",
              "      <td>2063.520020</td>\n",
              "      <td>2060.989990</td>\n",
              "      <td>1411860000</td>\n",
              "      <td>2060.989990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-28</th>\n",
              "      <td>2057.770020</td>\n",
              "      <td>2044.199951</td>\n",
              "      <td>2057.770020</td>\n",
              "      <td>2056.500000</td>\n",
              "      <td>2492510000</td>\n",
              "      <td>2056.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-29</th>\n",
              "      <td>2081.560059</td>\n",
              "      <td>2060.540039</td>\n",
              "      <td>2060.540039</td>\n",
              "      <td>2078.360107</td>\n",
              "      <td>2542000000</td>\n",
              "      <td>2078.360107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-30</th>\n",
              "      <td>2077.340088</td>\n",
              "      <td>2061.969971</td>\n",
              "      <td>2077.340088</td>\n",
              "      <td>2063.360107</td>\n",
              "      <td>2367430000</td>\n",
              "      <td>2063.360107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-31</th>\n",
              "      <td>2062.540039</td>\n",
              "      <td>2043.619995</td>\n",
              "      <td>2060.590088</td>\n",
              "      <td>2043.939941</td>\n",
              "      <td>2655330000</td>\n",
              "      <td>2043.939941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>652 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ff54016-34c6-4014-aa34-7b9fb2f702d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ff54016-34c6-4014-aa34-7b9fb2f702d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ff54016-34c6-4014-aa34-7b9fb2f702d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp500['zopen']=sp500['Open']/sp500['Close'] -1\n",
        "sp500['zhigh']=sp500['High']/sp500['Close'] -1\n",
        "sp500['zlow']=sp500['Low']/sp500['Close']-1"
      ],
      "metadata": {
        "id": "qwhnzFVmEEB7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp500['zclose']=-123320\n",
        "sp500['zadjclose']=-123320\n",
        "sp500['z5']=-123320\n",
        "sp500['z10']=-123320\n",
        "sp500['z15']=-123320\n",
        "sp500['z20']=-123320\n",
        "sp500['z25']=-123320\n",
        "sp500['z30']=-123320"
      ],
      "metadata": {
        "id": "Dj1oL0XWFjFk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sp500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBxLnBJOG7Dh",
        "outputId": "be7e78c4-a128-48b6-c05d-49cb8fc5b435"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "652"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,len(sp500)):\n",
        "  sp500.iloc[i,9]=sp500.iloc[i,3]/sp500.iloc[i-1,3] -1"
      ],
      "metadata": {
        "id": "7hJHdOSlHC4s"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,len(sp500)):\n",
        "  sp500.iloc[i,10]=sp500.iloc[i,5]/sp500.iloc[i-1,5] -1"
      ],
      "metadata": {
        "id": "eMH_yBeVH8vD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4,len(sp500)):\n",
        "  mysum=0\n",
        "  for j in range(5):\n",
        "    mysum=mysum+sp500.iloc[i-j,5]\n",
        "  sp500.iloc[i,11]=mysum/(5*sp500.iloc[i,5]) -1"
      ],
      "metadata": {
        "id": "k57pt9OQIYId"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(9,len(sp500)):\n",
        "  mysum=0\n",
        "  for j in range(10):\n",
        "    mysum=mysum+sp500.iloc[i-j,5]\n",
        "  sp500.iloc[i,12]=mysum/(10*sp500.iloc[i,5]) -1\n",
        "\n",
        "for i in range(14,len(sp500)):\n",
        "  mysum=0\n",
        "  for j in range(15):\n",
        "    mysum=mysum+sp500.iloc[i-j,5]\n",
        "  sp500.iloc[i,13]=mysum/(15*sp500.iloc[i,5]) -1\n",
        "\n",
        "for i in range(19,len(sp500)):\n",
        "  mysum=0\n",
        "  for j in range(20):\n",
        "    mysum=mysum+sp500.iloc[i-j,5]\n",
        "  sp500.iloc[i,14]=mysum/(20*sp500.iloc[i,5]) -1\n",
        "\n",
        "for i in range(24,len(sp500)):\n",
        "  mysum=0\n",
        "  for j in range(25):\n",
        "    mysum=mysum+sp500.iloc[i-j,5]\n",
        "  sp500.iloc[i,15]=mysum/(25*sp500.iloc[i,5]) -1\n",
        "\n",
        "for i in range(29,len(sp500)):\n",
        "  mysum=0\n",
        "  for j in range(30):\n",
        "    mysum=mysum+sp500.iloc[i-j,5]\n",
        "  sp500.iloc[i,16]=mysum/(30*sp500.iloc[i,5]) -1"
      ],
      "metadata": {
        "id": "0twZKeu5Jk0X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sp500 = sp500.iloc[:,6:]"
      ],
      "metadata": {
        "id": "7hT30NinKWcH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sp500.iloc[28]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTNdjo5aKmbk",
        "outputId": "cbb10d4f-bb28-415a-9a5f-38cdf5da4c67"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "zopen            -0.002934\n",
              "zhigh             0.000000\n",
              "zlow             -0.004678\n",
              "zclose            0.003086\n",
              "zadjclose         0.003086\n",
              "z5               -0.011944\n",
              "z10              -0.024918\n",
              "z15              -0.033711\n",
              "z20              -0.033206\n",
              "z25              -0.032273\n",
              "z30         -123320.000000\n",
              "Name: 2013-07-12 00:00:00, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sp500.iloc[:29,:]=-123320"
      ],
      "metadata": {
        "id": "nDcKfUx_K5V8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sp500.iloc[29]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EfmXoVgLCD7",
        "outputId": "96b33b06-1206-4956-931e-ef93f4639bbf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "zopen       -0.001730\n",
              "zhigh        0.001195\n",
              "zlow        -0.002740\n",
              "zclose       0.001375\n",
              "zadjclose    0.001375\n",
              "z5          -0.008303\n",
              "z10         -0.021727\n",
              "z15         -0.031469\n",
              "z20         -0.032876\n",
              "z25         -0.032671\n",
              "z30         -0.032493\n",
              "Name: 2013-07-15 00:00:00, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sp500.to_csv('sp500_acl18.csv', header=False, index=False)"
      ],
      "metadata": {
        "id": "0t593J41LuZE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJE_DE-RLHk4",
        "outputId": "efed44ec-19f0-43ce-d932-09fef73c4fbb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade pandas-datareader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "83jFQicYC4YE",
        "outputId": "16b708fa-9b59-48d1-c8bc-004e54d3c5aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Collecting pandas-datareader\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (1.3.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
            "Installing collected packages: pandas-datareader\n",
            "  Attempting uninstall: pandas-datareader\n",
            "    Found existing installation: pandas-datareader 0.9.0\n",
            "    Uninstalling pandas-datareader-0.9.0:\n",
            "      Successfully uninstalled pandas-datareader-0.9.0\n",
            "Successfully installed pandas-datareader-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas_datareader"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E5qApgKoC4pv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}